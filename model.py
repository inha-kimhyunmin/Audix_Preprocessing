from demucs.htdemucs import HTDemucs
import torch
from demucs.apply import apply_model
from config import MODEL_PATH, DEVICE, SOURCES, FORCE_STEREO_INPUT
from resample import maybe_resample

def load_model():
    """
    ëª¨ë¸ì„ ë¡œë“œí•˜ê³  í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •í•©ë‹ˆë‹¤.
    :return: (model, sources) íŠœí”Œ
    """
    print(f"ğŸ“¦ ëª¨ë¸ ë¡œë“œ ì¤‘ (Device: {DEVICE})")
    
    model = HTDemucs(sources=SOURCES)

    state_dict = torch.load(MODEL_PATH, map_location=DEVICE, weights_only=False)
    model.load_state_dict(state_dict, strict=False)

    model.to(DEVICE)
    model.eval()

    sources = model.sources if hasattr(model, 'sources') else [f"source_{i}" for i in range(getattr(model, 'nb_sources', 2))]
    return model, sources


def separate(model, audio_np):
    """
    ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ ëª¨ë¸ì— ì…ë ¥í•˜ì—¬ ì†ŒìŠ¤ ë¶„ë¦¬ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    :param model: ë¡œë“œëœ ëª¨ë¸
    :param audio_np: ì…ë ¥ ì˜¤ë””ì˜¤ ë°ì´í„° (numpy ë°°ì—´)
    :return: ë¶„ë¦¬ëœ ì†ŒìŠ¤ë“¤ (torch.Tensor)
    """
    # numpy to tensor ë° ì°¨ì› ì¡°ì •
    audio = torch.from_numpy(audio_np).float().unsqueeze(0)  # (samples,) â†’ (1, samples)

    if FORCE_STEREO_INPUT:  # ëª¨ë¸ì´ 2ì±„ë„ì„ ìš”êµ¬í•˜ëŠ” ê²½ìš° ë³µì œ
        audio = audio.repeat(2, 1)  # (1, samples) â†’ (2, samples)

    # (channels, samples) â†’ (batch=1, channels, samples)
    audio = audio.unsqueeze(0).to(DEVICE)

    audio = maybe_resample(audio)

    with torch.no_grad():
        sources = apply_model(model, audio, split=True, shifts=1, progress=False)[0]
    return sources.cpu()