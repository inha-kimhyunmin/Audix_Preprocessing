from demucs.htdemucs import HTDemucs
import torch
from torchaudio.transforms import Resample
from demucs.apply import apply_model
from config import MODEL_PATH, DEVICE, SAMPLE_RATE, SOURCES, FORCE_STEREO_INPUT
from monotostereo import mono_to_stereo
from resample import maybe_resample
import time

MAX_SAMPLES = 441000

def load_model():
    """
    ëª¨ë¸ì„ ë¡œë“œí•˜ê³  í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •í•©ë‹ˆë‹¤.
    :return: (model, sources) íŠœí”Œ
    """
    print(f"ğŸ“¦ ëª¨ë¸ ë¡œë“œ ì¤‘ (Device: {DEVICE})")
    
    model = HTDemucs(sources=SOURCES)

    state_dict = torch.load(MODEL_PATH, map_location=DEVICE)
    model.load_state_dict(state_dict, strict=False)

    model.to(DEVICE)
    model.eval()

    sources = model.sources if hasattr(model, 'sources') else [f"source_{i}" for i in range(getattr(model, 'nb_sources', 2))]
    return model, sources


def separate(model, audio_np):
    """
    ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ ëª¨ë¸ì— ì…ë ¥í•˜ì—¬ ì†ŒìŠ¤ ë¶„ë¦¬ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    :param model: ë¡œë“œëœ ëª¨ë¸
    :param audio_np: ì…ë ¥ ì˜¤ë””ì˜¤ ë°ì´í„° (numpy ë°°ì—´)
    :return: ë¶„ë¦¬ëœ ì†ŒìŠ¤ë“¤ (torch.Tensor)
    
    """
    audio = torch.tensor(audio_np, dtype=torch.float32).unsqueeze(1)  # (samples,) â†’ (samples, 1)

    if FORCE_STEREO_INPUT:  # í˜„ì¬ ëª¨ë¸ì´ 2ì±„ë„ì¼ ê²½ìš°ë§Œ ë³µì œ
        audio = audio.repeat(1, 2)  # (samples, 1) â†’ (samples, 2)

    # (samples, channels) â†’ (batch=1, channels, samples)
    audio = audio.transpose(0, 1).unsqueeze(0).to(DEVICE)

    audio = maybe_resample(audio)

    with torch.no_grad():
        sources = apply_model(model, audio, split=True, shifts=1, progress=False)[0]
    return sources.cpu()